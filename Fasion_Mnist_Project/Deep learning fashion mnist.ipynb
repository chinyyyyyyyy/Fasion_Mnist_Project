{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0        30        43   \n",
       "3       0    ...            3         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         1         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(r\"dataset\\fashion-mnist_train.csv\")\n",
    "test_df = pd.read_csv(r\"dataset\\fashion-mnist_test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.array(train_df, dtype='float32')\n",
    "test_data = np.array(test_df,dtype='float32')\n",
    "\n",
    "x_train = train_data[:,1:]/255\n",
    "y_train = train_data[:,0]\n",
    "\n",
    "x_test = test_data[:,1:]/255\n",
    "y_test = test_data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train,x_validate,y_train,y_validate = train_test_split(\n",
    "    x_train, y_train, test_size=0.2, random_state=12345,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = x_train[100,:].reshape((28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRErJLxKp/wcxaWmn778+igAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x204233e0978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape : (48000, 28, 28, 1)\n",
      "x_test shape : (10000, 28, 28, 1)\n",
      "x_validate shape : (12000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "im_rows = 28\n",
    "im_cols = 28\n",
    "batch_size = 512\n",
    "im_shape = (im_rows,im_cols,1)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],*im_shape)\n",
    "x_test = x_test.reshape(x_test.shape[0],*im_shape)\n",
    "x_validate = x_validate.reshape(x_validate.shape[0],*im_shape)\n",
    "\n",
    "print('x_train shape : {}'.format(x_train.shape))\n",
    "print('x_test shape : {}'.format(x_test.shape))\n",
    "print('x_validate shape : {}'.format(x_validate.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model = Sequential([\n",
    "    Conv2D(32, kernel_size=3, activation='relu', \n",
    "           input_shape=im_shape, kernel_initializer='he_normal', name='Conv2D-1'),\n",
    "    MaxPooling2D(pool_size=2, name='MaxPool'),\n",
    "    Dropout(0.25, name='Dropout-1'),\n",
    "    Conv2D(64, kernel_size=3, activation='relu', name='Conv2D-2'),\n",
    "    Dropout(0.25, name='Dropout-2'),\n",
    "    Conv2D(128, kernel_size=3, activation='relu', name='Conv2D-3'),\n",
    "    Dropout(0.4, name='Dropout-3'),\n",
    "    Conv2D(256, kernel_size=3, activation='relu', name='Conv2D-4'),\n",
    "    Dropout(0.6, name='Dropout-4'),\n",
    "    Flatten(name='flatten'),\n",
    "    Dense(256, activation='relu', name='Dense'),\n",
    "    Dropout(0.6, name='Dropout'),\n",
    "    Dense(10, activation='softmax', name='Output')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(\n",
    "    loss ='sparse_categorical_crossentropy',\n",
    "    optimizer = Adam(lr=0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 155s 3ms/step - loss: 0.9741 - acc: 0.6375 - val_loss: 0.5343 - val_acc: 0.7862\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 157s 3ms/step - loss: 0.5655 - acc: 0.7857 - val_loss: 0.4207 - val_acc: 0.8384\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 164s 3ms/step - loss: 0.4848 - acc: 0.8218 - val_loss: 0.3629 - val_acc: 0.8649\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 162s 3ms/step - loss: 0.4326 - acc: 0.8435 - val_loss: 0.3301 - val_acc: 0.8774\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 163s 3ms/step - loss: 0.3989 - acc: 0.8572 - val_loss: 0.3122 - val_acc: 0.8845\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 152s 3ms/step - loss: 0.3728 - acc: 0.8659 - val_loss: 0.2930 - val_acc: 0.8917\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 147s 3ms/step - loss: 0.3482 - acc: 0.8735 - val_loss: 0.2815 - val_acc: 0.8963\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 150s 3ms/step - loss: 0.3347 - acc: 0.8805 - val_loss: 0.2615 - val_acc: 0.9037\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 152s 3ms/step - loss: 0.3199 - acc: 0.8847 - val_loss: 0.2521 - val_acc: 0.9069\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 148s 3ms/step - loss: 0.3069 - acc: 0.8880 - val_loss: 0.2553 - val_acc: 0.9062\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 153s 3ms/step - loss: 0.3009 - acc: 0.8928 - val_loss: 0.2409 - val_acc: 0.9109\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 149s 3ms/step - loss: 0.2847 - acc: 0.8974 - val_loss: 0.2341 - val_acc: 0.9129\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 139s 3ms/step - loss: 0.2783 - acc: 0.8979 - val_loss: 0.2328 - val_acc: 0.9138\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 139s 3ms/step - loss: 0.2678 - acc: 0.9027 - val_loss: 0.2310 - val_acc: 0.9150\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 138s 3ms/step - loss: 0.2633 - acc: 0.9035 - val_loss: 0.2209 - val_acc: 0.9176\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 138s 3ms/step - loss: 0.2549 - acc: 0.9062 - val_loss: 0.2197 - val_acc: 0.9188\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 138s 3ms/step - loss: 0.2535 - acc: 0.9079 - val_loss: 0.2134 - val_acc: 0.9209\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 137s 3ms/step - loss: 0.2450 - acc: 0.9102 - val_loss: 0.2149 - val_acc: 0.9203\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 137s 3ms/step - loss: 0.2429 - acc: 0.9094 - val_loss: 0.2100 - val_acc: 0.9223\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 137s 3ms/step - loss: 0.2362 - acc: 0.9141 - val_loss: 0.2091 - val_acc: 0.9209\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 137s 3ms/step - loss: 0.2298 - acc: 0.9155 - val_loss: 0.2085 - val_acc: 0.9232\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 137s 3ms/step - loss: 0.2278 - acc: 0.9158 - val_loss: 0.2015 - val_acc: 0.9252\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 138s 3ms/step - loss: 0.2259 - acc: 0.9175 - val_loss: 0.2040 - val_acc: 0.9244\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 139s 3ms/step - loss: 0.2229 - acc: 0.9176 - val_loss: 0.1986 - val_acc: 0.9268\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 143s 3ms/step - loss: 0.2159 - acc: 0.9202 - val_loss: 0.2022 - val_acc: 0.9266\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 139s 3ms/step - loss: 0.2126 - acc: 0.9219 - val_loss: 0.1961 - val_acc: 0.9287\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 137s 3ms/step - loss: 0.2122 - acc: 0.9213 - val_loss: 0.1925 - val_acc: 0.9306\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 137s 3ms/step - loss: 0.2095 - acc: 0.9231 - val_loss: 0.1968 - val_acc: 0.9278\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 137s 3ms/step - loss: 0.2112 - acc: 0.9219 - val_loss: 0.1982 - val_acc: 0.9282\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 151s 3ms/step - loss: 0.2017 - acc: 0.9254 - val_loss: 0.1933 - val_acc: 0.9298\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 151s 3ms/step - loss: 0.2023 - acc: 0.9243 - val_loss: 0.1925 - val_acc: 0.9291\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 151s 3ms/step - loss: 0.1960 - acc: 0.9260 - val_loss: 0.1927 - val_acc: 0.9309\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 151s 3ms/step - loss: 0.1988 - acc: 0.9262 - val_loss: 0.2021 - val_acc: 0.9283\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 150s 3ms/step - loss: 0.1960 - acc: 0.9266 - val_loss: 0.1912 - val_acc: 0.9323\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 148s 3ms/step - loss: 0.1920 - acc: 0.9276 - val_loss: 0.1906 - val_acc: 0.9302\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 143s 3ms/step - loss: 0.1922 - acc: 0.9279 - val_loss: 0.1860 - val_acc: 0.9316\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 139s 3ms/step - loss: 0.1862 - acc: 0.9309 - val_loss: 0.1899 - val_acc: 0.9299\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 150s 3ms/step - loss: 0.1856 - acc: 0.9314 - val_loss: 0.1850 - val_acc: 0.9320\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 141s 3ms/step - loss: 0.1850 - acc: 0.9301 - val_loss: 0.1862 - val_acc: 0.9323\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 140s 3ms/step - loss: 0.1821 - acc: 0.9320 - val_loss: 0.1841 - val_acc: 0.9325\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 140s 3ms/step - loss: 0.1806 - acc: 0.9324 - val_loss: 0.1842 - val_acc: 0.9322\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 144s 3ms/step - loss: 0.1783 - acc: 0.9329 - val_loss: 0.1871 - val_acc: 0.9328\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 142s 3ms/step - loss: 0.1776 - acc: 0.9334 - val_loss: 0.1865 - val_acc: 0.9313\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 145s 3ms/step - loss: 0.1784 - acc: 0.9338 - val_loss: 0.1935 - val_acc: 0.9315\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 140s 3ms/step - loss: 0.1763 - acc: 0.9352 - val_loss: 0.1874 - val_acc: 0.9326\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 143s 3ms/step - loss: 0.1717 - acc: 0.9351 - val_loss: 0.1828 - val_acc: 0.9353\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 149s 3ms/step - loss: 0.1728 - acc: 0.9358 - val_loss: 0.1846 - val_acc: 0.9325\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 144s 3ms/step - loss: 0.1695 - acc: 0.9357 - val_loss: 0.1869 - val_acc: 0.9326\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 149s 3ms/step - loss: 0.1697 - acc: 0.9359 - val_loss: 0.1877 - val_acc: 0.9342\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 152s 3ms/step - loss: 0.1674 - acc: 0.9371 - val_loss: 0.1864 - val_acc: 0.9337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1291fb179b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(\n",
    "    x_train, y_train, batch_size=batch_size,\n",
    "    epochs=50, verbose=1,\n",
    "    validation_data=(x_validate,y_validate),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss : 0.181013\n",
      "test score : 0.938600\n"
     ]
    }
   ],
   "source": [
    "score = cnn_model.evaluate(x_test,y_test,verbose=0)\n",
    "\n",
    "print('test loss : {:4f}'.format(score[0]))\n",
    "print('test score : {:4f}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential([\n",
    "    Conv2D(32, kernel_size=3, activation='relu', \n",
    "           input_shape=im_shape, kernel_initializer='he_normal', name='Conv2D-1'),\n",
    "    MaxPooling2D(pool_size=2, name='MaxPool'),\n",
    "    Dropout(0.25, name='Dropout-1'),\n",
    "    Conv2D(64, kernel_size=3, activation='relu', name='Conv2D-2'),\n",
    "    Dropout(0.25, name='Dropout-2'),\n",
    "    Conv2D(128, kernel_size=3, activation='relu', name='Conv2D-3'),\n",
    "    Dropout(0.4, name='Dropout-3'),\n",
    "    Conv2D(256, kernel_size=3, activation='relu', name='Conv2D-4'),\n",
    "    Dropout(0.4, name='Dropout-4'),\n",
    "    Conv2D(512, kernel_size=3, activation='relu', name='Conv2D-5'),\n",
    "    Dropout(0.5, name='Dropout-5'),\n",
    "    Flatten(name='flatten'),\n",
    "    Dense(512, activation='relu', name='Dense'),\n",
    "    Dropout(0.5, name='Dropout'),\n",
    "    Dense(10, activation='softmax', name='Output')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(\n",
    "    loss ='sparse_categorical_crossentropy',\n",
    "    optimizer = Adam(lr=0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 336s 7ms/step - loss: 1.3839 - acc: 0.4928 - val_loss: 0.6842 - val_acc: 0.7364\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 337s 7ms/step - loss: 0.7512 - acc: 0.7144 - val_loss: 0.5701 - val_acc: 0.7783\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 351s 7ms/step - loss: 0.6401 - acc: 0.7570 - val_loss: 0.5013 - val_acc: 0.8003\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 337s 7ms/step - loss: 0.5722 - acc: 0.7856 - val_loss: 0.4600 - val_acc: 0.8255\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 335s 7ms/step - loss: 0.5203 - acc: 0.8082 - val_loss: 0.4001 - val_acc: 0.8527\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 334s 7ms/step - loss: 0.4740 - acc: 0.8270 - val_loss: 0.3684 - val_acc: 0.8642\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 337s 7ms/step - loss: 0.4440 - acc: 0.8391 - val_loss: 0.3501 - val_acc: 0.8698\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.4162 - acc: 0.8490 - val_loss: 0.3315 - val_acc: 0.8770\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.3990 - acc: 0.8547 - val_loss: 0.3174 - val_acc: 0.8815\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.3782 - acc: 0.8633 - val_loss: 0.3032 - val_acc: 0.8893\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 337s 7ms/step - loss: 0.3625 - acc: 0.8672 - val_loss: 0.3063 - val_acc: 0.8907\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 351s 7ms/step - loss: 0.3590 - acc: 0.8684 - val_loss: 0.2891 - val_acc: 0.8938\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.3461 - acc: 0.8734 - val_loss: 0.2777 - val_acc: 0.8975\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.3375 - acc: 0.8764 - val_loss: 0.2726 - val_acc: 0.8983\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 346s 7ms/step - loss: 0.3291 - acc: 0.8799 - val_loss: 0.2653 - val_acc: 0.9018\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.3251 - acc: 0.8813 - val_loss: 0.2619 - val_acc: 0.9027\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 337s 7ms/step - loss: 0.3152 - acc: 0.8849 - val_loss: 0.2588 - val_acc: 0.9053\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 339s 7ms/step - loss: 0.3126 - acc: 0.8866 - val_loss: 0.2648 - val_acc: 0.9003\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.3044 - acc: 0.8883 - val_loss: 0.2718 - val_acc: 0.8996\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 340s 7ms/step - loss: 0.3005 - acc: 0.8901 - val_loss: 0.2490 - val_acc: 0.9078\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 337s 7ms/step - loss: 0.2970 - acc: 0.8913 - val_loss: 0.2398 - val_acc: 0.9111\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 337s 7ms/step - loss: 0.2935 - acc: 0.8924 - val_loss: 0.2393 - val_acc: 0.9115\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 337s 7ms/step - loss: 0.2885 - acc: 0.8955 - val_loss: 0.2388 - val_acc: 0.9074\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 337s 7ms/step - loss: 0.2846 - acc: 0.8959 - val_loss: 0.2379 - val_acc: 0.9114\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.2786 - acc: 0.8981 - val_loss: 0.2397 - val_acc: 0.9111\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 337s 7ms/step - loss: 0.2766 - acc: 0.8987 - val_loss: 0.2325 - val_acc: 0.9122\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 337s 7ms/step - loss: 0.2704 - acc: 0.9009 - val_loss: 0.2394 - val_acc: 0.9119\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.2657 - acc: 0.9025 - val_loss: 0.2243 - val_acc: 0.9162\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.2632 - acc: 0.9036 - val_loss: 0.2295 - val_acc: 0.9161\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.2584 - acc: 0.9049 - val_loss: 0.2264 - val_acc: 0.9168\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.2586 - acc: 0.9046 - val_loss: 0.2213 - val_acc: 0.9155\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.2531 - acc: 0.9081 - val_loss: 0.2262 - val_acc: 0.9163\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.2516 - acc: 0.9067 - val_loss: 0.2175 - val_acc: 0.9171\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 337s 7ms/step - loss: 0.2512 - acc: 0.9075 - val_loss: 0.2138 - val_acc: 0.9212\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 337s 7ms/step - loss: 0.2419 - acc: 0.9115 - val_loss: 0.2102 - val_acc: 0.9221\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.2395 - acc: 0.9127 - val_loss: 0.2274 - val_acc: 0.9159\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.2381 - acc: 0.9120 - val_loss: 0.2158 - val_acc: 0.9208\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.2366 - acc: 0.9139 - val_loss: 0.2085 - val_acc: 0.9226\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.2333 - acc: 0.9136 - val_loss: 0.2085 - val_acc: 0.9241\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.2313 - acc: 0.9150 - val_loss: 0.2073 - val_acc: 0.9229\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.2322 - acc: 0.9144 - val_loss: 0.2066 - val_acc: 0.9219\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 337s 7ms/step - loss: 0.2284 - acc: 0.9161 - val_loss: 0.2028 - val_acc: 0.9251\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 337s 7ms/step - loss: 0.2254 - acc: 0.9184 - val_loss: 0.2073 - val_acc: 0.9216\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.2234 - acc: 0.9170 - val_loss: 0.2060 - val_acc: 0.9235\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.2192 - acc: 0.9198 - val_loss: 0.2065 - val_acc: 0.9235\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.2215 - acc: 0.9184 - val_loss: 0.2026 - val_acc: 0.9244\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.2210 - acc: 0.9199 - val_loss: 0.2035 - val_acc: 0.9237\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.2155 - acc: 0.9210 - val_loss: 0.2020 - val_acc: 0.9252\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 338s 7ms/step - loss: 0.2163 - acc: 0.9205 - val_loss: 0.1980 - val_acc: 0.9267\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 339s 7ms/step - loss: 0.2131 - acc: 0.9206 - val_loss: 0.2016 - val_acc: 0.9245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12964e34a90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(\n",
    "    x_train, y_train, batch_size=batch_size,\n",
    "    epochs=50, verbose=1,\n",
    "    validation_data=(x_validate,y_validate),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
